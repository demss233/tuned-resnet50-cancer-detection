{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":505351,"sourceType":"datasetVersion","datasetId":174469}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport random\nimport math\nimport glob\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport PIL\nfrom PIL import Image\n\nimport torch \nimport torch.nn as nn\nfrom torchvision import transforms\nfrom torchvision import datasets, models\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T21:15:56.679154Z","iopub.execute_input":"2025-09-21T21:15:56.679956Z","iopub.status.idle":"2025-09-21T21:15:56.684546Z","shell.execute_reply.started":"2025-09-21T21:15:56.679923Z","shell.execute_reply":"2025-09-21T21:15:56.683902Z"}},"outputs":[],"execution_count":173},{"cell_type":"code","source":"print(torch.__version__)\nprint(torch.cuda)\nprint(torch.cuda.is_available())\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T21:15:56.686029Z","iopub.execute_input":"2025-09-21T21:15:56.686267Z","iopub.status.idle":"2025-09-21T21:15:56.703566Z","shell.execute_reply.started":"2025-09-21T21:15:56.686251Z","shell.execute_reply":"2025-09-21T21:15:56.703045Z"}},"outputs":[{"name":"stdout","text":"2.6.0+cu124\n<module 'torch.cuda' from '/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py'>\nTrue\n","output_type":"stream"}],"execution_count":174},{"cell_type":"code","source":"root_train = '/kaggle/input/skin-cancer-malignant-vs-benign/train'\nroot_test = '/kaggle/input/skin-cancer-malignant-vs-benign/test'\n\ndef get_path(path, ty = 'train'):\n    paths = glob.glob(path + '/*')\n    return paths[0], paths[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T21:15:56.704223Z","iopub.execute_input":"2025-09-21T21:15:56.704817Z","iopub.status.idle":"2025-09-21T21:15:56.715967Z","shell.execute_reply.started":"2025-09-21T21:15:56.704794Z","shell.execute_reply":"2025-09-21T21:15:56.715448Z"}},"outputs":[],"execution_count":175},{"cell_type":"code","source":"def merge_results(benign, malignant):\n    files = []\n\n    benign = glob.glob(benign + '/*')\n    malignant = glob.glob(malignant + '/*')\n    \n    for image in benign:\n        files.append({\n            'path': image,\n            'malignant': 0,\n        })\n    \n    for image in malignant:\n        files.append({\n            'path': image,\n            'malignant': 1,\n        })\n    \n    random.shuffle(files)\n    return files","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T21:15:56.716729Z","iopub.execute_input":"2025-09-21T21:15:56.716964Z","iopub.status.idle":"2025-09-21T21:15:56.729553Z","shell.execute_reply.started":"2025-09-21T21:15:56.716944Z","shell.execute_reply":"2025-09-21T21:15:56.728773Z"}},"outputs":[],"execution_count":176},{"cell_type":"code","source":"img_transform = {\n    'valid': transforms.Compose([\n        transforms.Resize(size = 256),\n        transforms.CenterCrop(size = 224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(size = 256),\n        transforms.RandomRotation(degrees = 30),\n        transforms.ColorJitter(),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.CenterCrop(size = 224),  \n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])  \n    ]),\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T21:15:56.731357Z","iopub.execute_input":"2025-09-21T21:15:56.731547Z","iopub.status.idle":"2025-09-21T21:15:56.744468Z","shell.execute_reply.started":"2025-09-21T21:15:56.731534Z","shell.execute_reply":"2025-09-21T21:15:56.743721Z"}},"outputs":[],"execution_count":177},{"cell_type":"code","source":"class Configure(torch.utils.data.Dataset):\n    def __init__(self, images, transform = None):\n        super(Configure, self).__init__()\n        self.images = images\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]['path']\n        image = Image.open(image)\n        if self.transform is not None:\n            image = self.transform(image)\n\n        return image.to(device), torch.tensor(self.images[idx]['malignant'], dtype = torch.long).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T21:15:56.745093Z","iopub.execute_input":"2025-09-21T21:15:56.745247Z","iopub.status.idle":"2025-09-21T21:15:56.752794Z","shell.execute_reply.started":"2025-09-21T21:15:56.745234Z","shell.execute_reply":"2025-09-21T21:15:56.752125Z"}},"outputs":[],"execution_count":178},{"cell_type":"code","source":"benign_train, malignant_test = get_path(root_train)\nbenign_test, malignant_test = get_path(root_test)\n\ntrain_set = merge_results(benign_train, malignant_train)\ntest_set = merge_results(benign_test, malignant_test)\n\ntrainset = Configure(images = train_set, transform = img_transform['train'])\nvalidset = Configure(images = test_set, transform = img_transform['valid'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T21:15:56.753508Z","iopub.execute_input":"2025-09-21T21:15:56.753709Z","iopub.status.idle":"2025-09-21T21:15:56.778018Z","shell.execute_reply.started":"2025-09-21T21:15:56.753690Z","shell.execute_reply":"2025-09-21T21:15:56.777509Z"}},"outputs":[],"execution_count":179},{"cell_type":"code","source":"BATCH_SIZE = 4\nNUM_WORKERS = 0\n\ntrainloader = torch.utils.data.DataLoader(\n    trainset,\n    batch_size = BATCH_SIZE,\n    num_workers = NUM_WORKERS,\n    shuffle = True,\n)\n\ntestloader = torch.utils.data.DataLoader(\n    validset,\n    batch_size = BATCH_SIZE,\n    num_workers = NUM_WORKERS,\n    shuffle = False,\n)\n\nloaders = {\n    'train': trainloader,\n    'valid': testloader,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T21:15:56.778627Z","iopub.execute_input":"2025-09-21T21:15:56.778852Z","iopub.status.idle":"2025-09-21T21:15:56.783696Z","shell.execute_reply.started":"2025-09-21T21:15:56.778837Z","shell.execute_reply":"2025-09-21T21:15:56.783040Z"}},"outputs":[],"execution_count":180},{"cell_type":"code","source":"X, y = next(iter(trainloader))\nX2, y2 = next(iter(testloader))\nprint(X.shape, y.shape)\nprint(X2.shape, y2.shape)\n\nassert(X.shape == X2.shape)\nassert(y[0].dim() == y2[0].dim() == 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T21:15:56.784440Z","iopub.execute_input":"2025-09-21T21:15:56.784666Z","iopub.status.idle":"2025-09-21T21:15:56.829472Z","shell.execute_reply.started":"2025-09-21T21:15:56.784652Z","shell.execute_reply":"2025-09-21T21:15:56.828890Z"}},"outputs":[{"name":"stdout","text":"torch.Size([4, 3, 224, 224]) torch.Size([4])\ntorch.Size([4, 3, 224, 224]) torch.Size([4])\n","output_type":"stream"}],"execution_count":181},{"cell_type":"code","source":"use_cuda = torch.cuda.is_available()\n\nmodel_resnet = models.resnet50(pretrained = True)\nfor param in model_resnet.parameters():\n    param.requires_grad = False\n    \nin_features = model_resnet.fc.in_features\nmodel_resnet.fc = nn.Linear(in_features, 64)\nmodel_resnet.bn_fc = nn.BatchNorm2d(128)\nmodel_resnet.drop = nn.Dropout(0.6)\nmodel_resnet.fc2 = nn.Linear(128, 2)\n\nif use_cuda:\n    model_resnet = model_resnet.cuda()\n\nprint(model_resnet)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T21:15:56.830186Z","iopub.execute_input":"2025-09-21T21:15:56.830421Z","iopub.status.idle":"2025-09-21T21:15:57.296282Z","shell.execute_reply.started":"2025-09-21T21:15:56.830406Z","shell.execute_reply":"2025-09-21T21:15:57.295597Z"}},"outputs":[{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=64, bias=True)\n  (bn_fc): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (drop): Dropout(p=0.6, inplace=False)\n  (fc2): Linear(in_features=128, out_features=2, bias=True)\n)\n","output_type":"stream"}],"execution_count":182},{"cell_type":"code","source":"criterion_resnet = nn.CrossEntropyLoss()\ngrad_parameters_resnet = filter(lambda p: p.requires_grad, model_resnet.parameters())\noptimizer_resnet = torch.optim.SGD(grad_parameters_resnet, lr = 1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T21:15:57.296936Z","iopub.execute_input":"2025-09-21T21:15:57.297139Z","iopub.status.idle":"2025-09-21T21:15:57.301493Z","shell.execute_reply.started":"2025-09-21T21:15:57.297125Z","shell.execute_reply":"2025-09-21T21:15:57.300937Z"}},"outputs":[],"execution_count":183},{"cell_type":"code","source":"n_epochs = 20\n\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer = optimizer_resnet,\n    max_lr = 1e-2,\n    steps_per_epoch = len(trainset) // BATCH_SIZE,\n    epochs = n_epochs\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T21:15:57.303065Z","iopub.execute_input":"2025-09-21T21:15:57.303312Z","iopub.status.idle":"2025-09-21T21:15:57.314352Z","shell.execute_reply.started":"2025-09-21T21:15:57.303295Z","shell.execute_reply":"2025-09-21T21:15:57.313818Z"}},"outputs":[],"execution_count":184},{"cell_type":"code","source":"def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, early_stopping_rounds, save_path):\n    valid_loss_min = np.Inf \n    early_stopping_counter = 0\n    \n    for epoch in range(1, n_epochs + 1):\n        train_loss = 0.0\n        valid_loss = 0.0\n        model.train()\n        for batch_idx, (data, target) in enumerate(loaders['train']):\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            \n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            \n            loss.backward()\n            optimizer.step()\n            # scheduler.step()\n            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n            if batch_idx % 100 == 0:\n                print('Epoch: %d \\tBatch: %d \\tTraining Loss: %.6f \\tLearning Rate: %.6f' %(epoch, batch_idx + 1, train_loss, optimizer.param_groups[0]['lr']))\n\n        model.eval()\n        for batch_idx, (data, target) in enumerate(loaders['valid']):\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            \n            output = model(data)\n            loss = criterion(output, target)\n            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n            \n        print('Epoch: {} \\tTraining Loss: {:.4f} \\tValidation Loss: {:.4f}'.format(epoch, train_loss, valid_loss))\n        if valid_loss < valid_loss_min:\n            early_stopping_counter = 0\n            torch.save(model.state_dict(), save_path)\n            print('\\nBOOM! Validation loss decreased ({:.4f} --> {:.4f}).  Saving model...\\n'.format(valid_loss_min,valid_loss))\n            valid_loss_min = valid_loss    \n        else:\n            early_stopping_counter += 1\n            if early_stopping_counter >= early_stopping_rounds:\n                break\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T21:15:57.314957Z","iopub.execute_input":"2025-09-21T21:15:57.315229Z","iopub.status.idle":"2025-09-21T21:15:57.330730Z","shell.execute_reply.started":"2025-09-21T21:15:57.315207Z","shell.execute_reply":"2025-09-21T21:15:57.330043Z"}},"outputs":[],"execution_count":185},{"cell_type":"code","source":"model_resnet = train(\n    n_epochs,\n    loaders = loaders,\n    model = model_resnet,\n    optimizer = optimizer_resnet,\n    criterion = criterion_resnet,\n    use_cuda = use_cuda,\n    early_stopping_rounds = 10,\n    save_path = 'cancer_resnet50'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T21:15:57.331506Z","iopub.execute_input":"2025-09-21T21:15:57.331719Z","iopub.status.idle":"2025-09-21T21:19:38.026377Z","shell.execute_reply.started":"2025-09-21T21:15:57.331696Z","shell.execute_reply":"2025-09-21T21:19:38.025607Z"}},"outputs":[{"name":"stdout","text":"Epoch: 1 \tBatch: 1 \tTraining Loss: 4.551740 \tLearning Rate: 0.000400\nEpoch: 1 \tBatch: 101 \tTraining Loss: 0.993620 \tLearning Rate: 0.000400\nEpoch: 1 \tBatch: 201 \tTraining Loss: 0.744818 \tLearning Rate: 0.000400\nEpoch: 1 \tBatch: 301 \tTraining Loss: 0.630239 \tLearning Rate: 0.000400\nEpoch: 1 \tBatch: 401 \tTraining Loss: 0.562988 \tLearning Rate: 0.000400\nEpoch: 1 \tTraining Loss: 0.5484 \tValidation Loss: 0.9141\n\nBOOM! Validation loss decreased (inf --> 0.9141).  Saving model...\n\nEpoch: 2 \tBatch: 1 \tTraining Loss: 0.143032 \tLearning Rate: 0.000400\nEpoch: 2 \tBatch: 101 \tTraining Loss: 0.367012 \tLearning Rate: 0.000400\nEpoch: 2 \tBatch: 201 \tTraining Loss: 0.365430 \tLearning Rate: 0.000400\nEpoch: 2 \tBatch: 301 \tTraining Loss: 0.376709 \tLearning Rate: 0.000400\nEpoch: 2 \tBatch: 401 \tTraining Loss: 0.365494 \tLearning Rate: 0.000400\nEpoch: 2 \tTraining Loss: 0.3610 \tValidation Loss: 0.8859\n\nBOOM! Validation loss decreased (0.9141 --> 0.8859).  Saving model...\n\nEpoch: 3 \tBatch: 1 \tTraining Loss: 0.141071 \tLearning Rate: 0.000400\nEpoch: 3 \tBatch: 101 \tTraining Loss: 0.389995 \tLearning Rate: 0.000400\nEpoch: 3 \tBatch: 201 \tTraining Loss: 0.369911 \tLearning Rate: 0.000400\nEpoch: 3 \tBatch: 301 \tTraining Loss: 0.379371 \tLearning Rate: 0.000400\nEpoch: 3 \tBatch: 401 \tTraining Loss: 0.380081 \tLearning Rate: 0.000400\nEpoch: 3 \tTraining Loss: 0.3763 \tValidation Loss: 1.2933\nEpoch: 4 \tBatch: 1 \tTraining Loss: 1.345282 \tLearning Rate: 0.000400\nEpoch: 4 \tBatch: 101 \tTraining Loss: 0.433378 \tLearning Rate: 0.000400\nEpoch: 4 \tBatch: 201 \tTraining Loss: 0.399321 \tLearning Rate: 0.000400\nEpoch: 4 \tBatch: 301 \tTraining Loss: 0.388336 \tLearning Rate: 0.000400\nEpoch: 4 \tBatch: 401 \tTraining Loss: 0.378748 \tLearning Rate: 0.000400\nEpoch: 4 \tTraining Loss: 0.3691 \tValidation Loss: 0.6358\n\nBOOM! Validation loss decreased (0.8859 --> 0.6358).  Saving model...\n\nEpoch: 5 \tBatch: 1 \tTraining Loss: 0.294948 \tLearning Rate: 0.000400\nEpoch: 5 \tBatch: 101 \tTraining Loss: 0.357003 \tLearning Rate: 0.000400\nEpoch: 5 \tBatch: 201 \tTraining Loss: 0.334912 \tLearning Rate: 0.000400\nEpoch: 5 \tBatch: 301 \tTraining Loss: 0.370983 \tLearning Rate: 0.000400\nEpoch: 5 \tBatch: 401 \tTraining Loss: 0.386543 \tLearning Rate: 0.000400\nEpoch: 5 \tTraining Loss: 0.3820 \tValidation Loss: 0.6611\nEpoch: 6 \tBatch: 1 \tTraining Loss: 0.140077 \tLearning Rate: 0.000400\nEpoch: 6 \tBatch: 101 \tTraining Loss: 0.380445 \tLearning Rate: 0.000400\nEpoch: 6 \tBatch: 201 \tTraining Loss: 0.368929 \tLearning Rate: 0.000400\nEpoch: 6 \tBatch: 301 \tTraining Loss: 0.376970 \tLearning Rate: 0.000400\nEpoch: 6 \tBatch: 401 \tTraining Loss: 0.373899 \tLearning Rate: 0.000400\nEpoch: 6 \tTraining Loss: 0.3728 \tValidation Loss: 0.3833\n\nBOOM! Validation loss decreased (0.6358 --> 0.3833).  Saving model...\n\nEpoch: 7 \tBatch: 1 \tTraining Loss: 0.383493 \tLearning Rate: 0.000400\nEpoch: 7 \tBatch: 101 \tTraining Loss: 0.354320 \tLearning Rate: 0.000400\nEpoch: 7 \tBatch: 201 \tTraining Loss: 0.350743 \tLearning Rate: 0.000400\nEpoch: 7 \tBatch: 301 \tTraining Loss: 0.337127 \tLearning Rate: 0.000400\nEpoch: 7 \tBatch: 401 \tTraining Loss: 0.346140 \tLearning Rate: 0.000400\nEpoch: 7 \tTraining Loss: 0.3460 \tValidation Loss: 0.7085\nEpoch: 8 \tBatch: 1 \tTraining Loss: 0.081267 \tLearning Rate: 0.000400\nEpoch: 8 \tBatch: 101 \tTraining Loss: 0.365439 \tLearning Rate: 0.000400\nEpoch: 8 \tBatch: 201 \tTraining Loss: 0.375800 \tLearning Rate: 0.000400\nEpoch: 8 \tBatch: 301 \tTraining Loss: 0.355291 \tLearning Rate: 0.000400\nEpoch: 8 \tBatch: 401 \tTraining Loss: 0.347549 \tLearning Rate: 0.000400\nEpoch: 8 \tTraining Loss: 0.3458 \tValidation Loss: 0.7193\nEpoch: 9 \tBatch: 1 \tTraining Loss: 0.247208 \tLearning Rate: 0.000400\nEpoch: 9 \tBatch: 101 \tTraining Loss: 0.285151 \tLearning Rate: 0.000400\nEpoch: 9 \tBatch: 201 \tTraining Loss: 0.311470 \tLearning Rate: 0.000400\nEpoch: 9 \tBatch: 301 \tTraining Loss: 0.333345 \tLearning Rate: 0.000400\nEpoch: 9 \tBatch: 401 \tTraining Loss: 0.327840 \tLearning Rate: 0.000400\nEpoch: 9 \tTraining Loss: 0.3312 \tValidation Loss: 0.8140\nEpoch: 10 \tBatch: 1 \tTraining Loss: 0.554651 \tLearning Rate: 0.000400\nEpoch: 10 \tBatch: 101 \tTraining Loss: 0.352595 \tLearning Rate: 0.000400\nEpoch: 10 \tBatch: 201 \tTraining Loss: 0.370022 \tLearning Rate: 0.000400\nEpoch: 10 \tBatch: 301 \tTraining Loss: 0.371426 \tLearning Rate: 0.000400\nEpoch: 10 \tBatch: 401 \tTraining Loss: 0.364090 \tLearning Rate: 0.000400\nEpoch: 10 \tTraining Loss: 0.3745 \tValidation Loss: 0.4476\nEpoch: 11 \tBatch: 1 \tTraining Loss: 0.334812 \tLearning Rate: 0.000400\nEpoch: 11 \tBatch: 101 \tTraining Loss: 0.344037 \tLearning Rate: 0.000400\nEpoch: 11 \tBatch: 201 \tTraining Loss: 0.375926 \tLearning Rate: 0.000400\nEpoch: 11 \tBatch: 301 \tTraining Loss: 0.361271 \tLearning Rate: 0.000400\nEpoch: 11 \tBatch: 401 \tTraining Loss: 0.378347 \tLearning Rate: 0.000400\nEpoch: 11 \tTraining Loss: 0.3733 \tValidation Loss: 0.4922\nEpoch: 12 \tBatch: 1 \tTraining Loss: 0.151796 \tLearning Rate: 0.000400\nEpoch: 12 \tBatch: 101 \tTraining Loss: 0.265546 \tLearning Rate: 0.000400\nEpoch: 12 \tBatch: 201 \tTraining Loss: 0.316493 \tLearning Rate: 0.000400\nEpoch: 12 \tBatch: 301 \tTraining Loss: 0.321379 \tLearning Rate: 0.000400\nEpoch: 12 \tBatch: 401 \tTraining Loss: 0.342736 \tLearning Rate: 0.000400\nEpoch: 12 \tTraining Loss: 0.3456 \tValidation Loss: 0.6754\nEpoch: 13 \tBatch: 1 \tTraining Loss: 0.227558 \tLearning Rate: 0.000400\nEpoch: 13 \tBatch: 101 \tTraining Loss: 0.351582 \tLearning Rate: 0.000400\nEpoch: 13 \tBatch: 201 \tTraining Loss: 0.383844 \tLearning Rate: 0.000400\nEpoch: 13 \tBatch: 301 \tTraining Loss: 0.355073 \tLearning Rate: 0.000400\nEpoch: 13 \tBatch: 401 \tTraining Loss: 0.369381 \tLearning Rate: 0.000400\nEpoch: 13 \tTraining Loss: 0.3680 \tValidation Loss: 0.6137\nEpoch: 14 \tBatch: 1 \tTraining Loss: 0.161762 \tLearning Rate: 0.000400\nEpoch: 14 \tBatch: 101 \tTraining Loss: 0.314202 \tLearning Rate: 0.000400\nEpoch: 14 \tBatch: 201 \tTraining Loss: 0.333424 \tLearning Rate: 0.000400\nEpoch: 14 \tBatch: 301 \tTraining Loss: 0.323554 \tLearning Rate: 0.000400\nEpoch: 14 \tBatch: 401 \tTraining Loss: 0.337522 \tLearning Rate: 0.000400\nEpoch: 14 \tTraining Loss: 0.3344 \tValidation Loss: 0.5611\nEpoch: 15 \tBatch: 1 \tTraining Loss: 0.196295 \tLearning Rate: 0.000400\nEpoch: 15 \tBatch: 101 \tTraining Loss: 0.439168 \tLearning Rate: 0.000400\nEpoch: 15 \tBatch: 201 \tTraining Loss: 0.408976 \tLearning Rate: 0.000400\nEpoch: 15 \tBatch: 301 \tTraining Loss: 0.394099 \tLearning Rate: 0.000400\nEpoch: 15 \tBatch: 401 \tTraining Loss: 0.375033 \tLearning Rate: 0.000400\nEpoch: 15 \tTraining Loss: 0.3742 \tValidation Loss: 0.5508\nEpoch: 16 \tBatch: 1 \tTraining Loss: 0.118913 \tLearning Rate: 0.000400\nEpoch: 16 \tBatch: 101 \tTraining Loss: 0.434110 \tLearning Rate: 0.000400\nEpoch: 16 \tBatch: 201 \tTraining Loss: 0.386421 \tLearning Rate: 0.000400\nEpoch: 16 \tBatch: 301 \tTraining Loss: 0.408674 \tLearning Rate: 0.000400\nEpoch: 16 \tBatch: 401 \tTraining Loss: 0.384200 \tLearning Rate: 0.000400\nEpoch: 16 \tTraining Loss: 0.3744 \tValidation Loss: 0.6317\n","output_type":"stream"}],"execution_count":186},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}